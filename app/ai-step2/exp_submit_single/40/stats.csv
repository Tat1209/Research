max_lr,weight_decay,epochs,batch_size,mixup,train_trans,val_trans,num_data,iters/epoch,dataset,model_arc,start_weight,params,params_trainable,loss_func,optimizer,scheduler,lr,epoch,train_loss,train_acc,train_f1,test_f1
0.00001,0.02,1000,128,true,"[ToTensor(), Lambda(), ColorJitter(brightness=(0.85, 1.15), contrast=(0.85, 1.15), saturation=None, hue=None), RandomAffine(degrees=[-15.0, 15.0], translate=(0.15, 0.15), scale=(0.85, 1.15), interpolation=bilinear), Normalize(mean=[0.18503567576408386, 0.27679356932640076, 0.43360984325408936], std=[0.08373230695724487, 0.07494986057281494, 0.06476051360368729])]","[ToTensor(), Lambda(), Normalize(mean=[0.18503567576408386, 0.27679356932640076, 0.43360984325408936], std=[0.08373230695724487, 0.07494986057281494, 0.06476051360368729])]",44058,345,ai-step_l,torchvision.models.efficientnet,/home/haselab/Documents/tat/Research/app/ai-step2/exp_tl/1/state_dict.pt,20186455,20186455,CrossEntropyLoss(),"Lion ( Parameter Group 0     betas: (0.9, 0.99)     foreach: None     initial_lr: 1e-05     lr: 1e-05     maximize: False     weight_decay: 0.02 )",CosineAnnealingLR ( T_max = 1000 base_lrs = [1e-05] eta_min = 0 last_epoch = 0 optimizer = Lion() verbose = False ),2.467399070893442e-11,1000,0.11426945994827839,0.9165773478307165,0.49571151478648295,59.462
