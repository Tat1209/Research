max_lr,weight_decay,epochs,batch_size,mixup,train_trans,val_trans,u_num_label,num_data,iters/epoch,dataset,model_arc,start_weight,params,params_trainable,loss_func,optimizer,scheduler,lr,epoch,train_loss,train_acc,train_f1,test_f1
0.001,0.00007,2000,128,true,"[ToTensor(), Lambda(), RandomHorizontalFlip(p=0.5), RandomVerticalFlip(p=0.5), ColorJitter(brightness=(0.5, 1.5), contrast=(0.5, 1.5), saturation=None, hue=None), RandomAffine(degrees=[-10.0, 10.0], translate=(0.1, 0.1), scale=(0.93, 1.07), interpolation=bilinear), Normalize(mean=[0.18503567576408386, 0.27679356932640076, 0.43360984325408936], std=[0.08373230695724487, 0.07494986057281494, 0.06476051360368729])]","[ToTensor(), Lambda(), Normalize(mean=[0.18503567576408386, 0.27679356932640076, 0.43360984325408936], std=[0.08373230695724487, 0.07494986057281494, 0.06476051360368729])]",4000,58645,459,ai-step_l,torchvision.models.efficientnet,/home/haselab/Documents/tat/Research/app/ai-step2/exp_tl/1/state_dict.pt,20186455,20186455,CrossEntropyLoss(),SGD ( Parameter Group 0     dampening: 0     differentiable: False     foreach: None     initial_lr: 0.001     lr: 0.001     maximize: False     momentum: 0.9     nesterov: False     weight_decay: 7e-05 ),CosineAnnealingLR ( T_max = 2000 base_lrs = [0.001] eta_min = 0 last_epoch = 0 optimizer = SGD() verbose = False ),6.168501482384237e-10,2000,0.20577706323489103,0.9024138590230266,0.5818705538359368,58.893
